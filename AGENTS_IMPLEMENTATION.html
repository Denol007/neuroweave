<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>NeuroWeave â€” Agent System Implementation Guide</title>
<script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
<style>
*,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
:root{
  --bg:#0a0a0b;--bg-card:#111113;--bg-card-hover:#18181b;--bg-sidebar:#0e0e10;
  --border:#1e1e22;--border-hover:#2a2a30;
  --text:#e4e4e7;--text-muted:#71717a;--text-dim:#52525b;
  --accent:#6366f1;--accent-hover:#818cf8;--accent-glow:rgba(99,102,241,.15);
  --green:#22c55e;--orange:#f97316;--red:#ef4444;--cyan:#06b6d4;--pink:#ec4899;
  --purple:#a855f7;--yellow:#eab308;
  --sidebar-w:260px;--header-h:0px;
  --radius:12px;--radius-sm:8px;
}
html{scroll-behavior:smooth;scrollbar-width:thin;scrollbar-color:#27272a #0a0a0b}
body{font-family:'Inter',system-ui,sans-serif;background:var(--bg);color:var(--text);line-height:1.7;overflow-x:hidden}
::-webkit-scrollbar{width:6px}::-webkit-scrollbar-track{background:var(--bg)}::-webkit-scrollbar-thumb{background:#27272a;border-radius:3px}

.sidebar{position:fixed;top:0;left:0;width:var(--sidebar-w);height:100vh;background:var(--bg-sidebar);border-right:1px solid var(--border);padding:24px 0;overflow-y:auto;z-index:100;transition:transform .3s ease}
.sidebar-logo{padding:0 20px 20px;border-bottom:1px solid var(--border);margin-bottom:16px}
.sidebar-logo h2{font-size:18px;font-weight:700;background:linear-gradient(135deg,var(--accent),var(--cyan));-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.sidebar-logo span{font-size:11px;color:var(--text-muted);display:block;margin-top:2px;letter-spacing:.5px;text-transform:uppercase}
.nav-section{padding:0 12px;margin-bottom:8px}
.nav-section-title{font-size:10px;text-transform:uppercase;letter-spacing:1.2px;color:var(--text-dim);padding:8px 12px 4px;font-weight:600}
.nav-link{display:flex;align-items:center;gap:8px;padding:7px 12px;color:var(--text-muted);text-decoration:none;font-size:13px;border-radius:var(--radius-sm);transition:all .15s;font-weight:450}
.nav-link:hover{color:var(--text);background:rgba(255,255,255,.04)}
.nav-link.active{color:var(--accent-hover);background:var(--accent-glow);font-weight:550}
.nav-link .nav-icon{width:18px;text-align:center;font-size:14px;flex-shrink:0}

.main{margin-left:var(--sidebar-w);min-height:100vh}

.hero{padding:100px 60px 80px;position:relative;overflow:hidden}
.hero::before{content:'';position:absolute;top:-200px;right:-200px;width:600px;height:600px;background:radial-gradient(circle,var(--accent-glow),transparent 70%);pointer-events:none}
.hero::after{content:'';position:absolute;bottom:-100px;left:-100px;width:400px;height:400px;background:radial-gradient(circle,rgba(6,182,212,.08),transparent 70%);pointer-events:none}
.hero-badge{display:inline-flex;align-items:center;gap:6px;padding:6px 14px;border:1px solid var(--border);border-radius:20px;font-size:12px;color:var(--text-muted);margin-bottom:24px;background:rgba(255,255,255,.02)}
.hero-badge .dot{width:6px;height:6px;border-radius:50%;background:var(--green);animation:pulse 2s infinite}
@keyframes pulse{0%,100%{opacity:1}50%{opacity:.4}}
.hero h1{font-size:clamp(36px,5vw,56px);font-weight:800;line-height:1.1;margin-bottom:16px;letter-spacing:-.02em}
.hero h1 .gradient{background:linear-gradient(135deg,var(--accent),var(--cyan),var(--purple));-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.hero .subtitle{font-size:clamp(16px,2vw,20px);color:var(--text-muted);max-width:700px;line-height:1.6;margin-bottom:48px}
.metrics{display:grid;grid-template-columns:repeat(auto-fit,minmax(160px,1fr));gap:16px;max-width:800px}
.metric{background:var(--bg-card);border:1px solid var(--border);border-radius:var(--radius);padding:20px;transition:all .2s}
.metric:hover{border-color:var(--border-hover);transform:translateY(-2px)}
.metric .value{font-size:28px;font-weight:700;color:var(--accent-hover);font-variant-numeric:tabular-nums}
.metric .label{font-size:12px;color:var(--text-muted);margin-top:4px;text-transform:uppercase;letter-spacing:.5px}

.section{padding:60px;border-top:1px solid var(--border);position:relative}
.section-header{margin-bottom:40px}
.section-number{font-size:12px;font-weight:600;color:var(--accent);text-transform:uppercase;letter-spacing:1.5px;margin-bottom:8px}
.section-title{font-size:clamp(24px,3vw,36px);font-weight:700;letter-spacing:-.01em}
.section-desc{color:var(--text-muted);margin-top:8px;font-size:15px;max-width:600px}

.card-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:20px}
.card{background:var(--bg-card);border:1px solid var(--border);border-radius:var(--radius);padding:28px;transition:all .25s;position:relative;overflow:hidden}
.card:hover{border-color:var(--border-hover);transform:translateY(-3px);box-shadow:0 12px 40px rgba(0,0,0,.3)}
.card::before{content:'';position:absolute;top:0;left:0;right:0;height:3px;border-radius:var(--radius) var(--radius) 0 0}
.card:nth-child(1)::before{background:linear-gradient(90deg,var(--accent),var(--cyan))}
.card:nth-child(2)::before{background:linear-gradient(90deg,var(--green),var(--cyan))}
.card:nth-child(3)::before{background:linear-gradient(90deg,var(--orange),var(--yellow))}
.card:nth-child(4)::before{background:linear-gradient(90deg,var(--pink),var(--purple))}
.card:nth-child(5)::before{background:linear-gradient(90deg,var(--purple),var(--accent))}
.card-icon{font-size:28px;margin-bottom:12px}
.card h3{font-size:17px;font-weight:650;margin-bottom:6px}
.card .card-sub{font-size:13px;color:var(--accent);margin-bottom:12px;font-weight:500}
.card p{font-size:13.5px;color:var(--text-muted);line-height:1.65}
.card .tech-tags{display:flex;flex-wrap:wrap;gap:6px;margin-top:14px}
.card .tech-tag{padding:3px 10px;background:rgba(255,255,255,.04);border:1px solid var(--border);border-radius:20px;font-size:11px;color:var(--text-muted);font-family:'JetBrains Mono',monospace}

.diagram-box{background:var(--bg-card);border:1px solid var(--border);border-radius:var(--radius);padding:32px;margin:24px 0;overflow-x:auto}
.diagram-box .mermaid{display:flex;justify-content:center}

.code-block{background:#0d0d10;border:1px solid var(--border);border-radius:var(--radius);overflow:hidden;margin:20px 0}
.code-header{display:flex;align-items:center;justify-content:space-between;padding:10px 16px;background:rgba(255,255,255,.02);border-bottom:1px solid var(--border)}
.code-lang{font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace;font-weight:500}
.code-body{padding:20px;overflow-x:auto;font-family:'JetBrains Mono',monospace;font-size:13px;line-height:1.7;color:#c9d1d9}
.code-body .kw{color:#ff7b72}.code-body .str{color:#a5d6ff}.code-body .cm{color:#8b949e;font-style:italic}
.code-body .fn{color:#d2a8ff}.code-body .tp{color:#79c0ff}.code-body .op{color:#ff7b72}.code-body .nb{color:#ffa657}
.code-body .key{color:#7ee787}.code-body .val{color:#a5d6ff}.code-body .num{color:#ffa657}
.code-body .dec{color:#ffa657}

.stages{display:flex;flex-direction:column;gap:0;position:relative}
.stage-connector{width:2px;height:32px;background:var(--border);margin:0 auto}
.stage{background:var(--bg-card);border:1px solid var(--border);border-radius:var(--radius);padding:24px 28px;position:relative;transition:all .25s}
.stage:hover{border-color:var(--accent);box-shadow:0 0 30px var(--accent-glow)}
.stage-num{position:absolute;top:-12px;left:24px;background:var(--accent);color:#fff;font-size:11px;font-weight:700;padding:2px 12px;border-radius:12px}
.stage h4{font-size:15px;font-weight:600;margin-bottom:8px;margin-top:4px}
.stage p,.stage ul{font-size:13px;color:var(--text-muted);line-height:1.7}
.stage ul{margin-left:16px;margin-top:6px}
.stage code{font-family:'JetBrains Mono',monospace;font-size:12px;background:rgba(255,255,255,.06);padding:2px 6px;border-radius:4px;color:var(--cyan)}

.pipeline{display:flex;align-items:center;gap:0;overflow-x:auto;padding:20px 0;flex-wrap:nowrap}
.pipeline-step{display:flex;flex-direction:column;align-items:center;min-width:120px;flex-shrink:0}
.pipeline-node{width:100px;height:100px;border-radius:50%;display:flex;flex-direction:column;align-items:center;justify-content:center;border:2px solid var(--border);background:var(--bg-card);transition:all .3s;cursor:default}
.pipeline-node:hover{border-color:var(--accent);transform:scale(1.08)}
.pipeline-node .p-icon{font-size:24px;margin-bottom:4px}
.pipeline-node .p-label{font-size:10px;color:var(--text-muted);text-align:center;font-weight:500}
.pipeline-arrow{color:var(--text-dim);font-size:20px;flex-shrink:0;margin:0 4px}
.pipeline-step-label{font-size:11px;color:var(--text-muted);margin-top:10px;text-align:center;max-width:100px}

/* TABS */
.tabs{display:flex;gap:4px;margin-bottom:0;border-bottom:1px solid var(--border);padding:0 4px}
.tab{padding:10px 20px;font-size:13px;font-weight:500;color:var(--text-muted);cursor:pointer;border:none;background:none;border-bottom:2px solid transparent;transition:all .2s;font-family:'Inter',system-ui,sans-serif}
.tab:hover{color:var(--text)}
.tab.active{color:var(--accent-hover);border-bottom-color:var(--accent)}
.tab-content{display:none;padding:24px;background:var(--bg-card);border:1px solid var(--border);border-top:none;border-radius:0 0 var(--radius) var(--radius)}
.tab-content.active{display:block}

/* STATE FIELD */
.state-field{display:flex;align-items:flex-start;gap:16px;padding:14px 0;border-bottom:1px solid rgba(255,255,255,.04)}
.state-field:last-child{border-bottom:none}
.state-field-name{min-width:180px;font-family:'JetBrains Mono',monospace;font-size:13px;color:var(--cyan);font-weight:500}
.state-field-type{min-width:140px;font-family:'JetBrains Mono',monospace;font-size:12px;color:var(--purple)}
.state-field-desc{font-size:13px;color:var(--text-muted);line-height:1.5}

/* STATE MUTATION VIS */
.state-timeline{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:16px;margin-top:24px}
.state-step{background:var(--bg-card);border:1px solid var(--border);border-radius:var(--radius-sm);padding:16px;position:relative}
.state-step::after{content:'';position:absolute;top:50%;right:-10px;border:5px solid transparent;border-left-color:var(--accent);display:none}
.state-step:not(:last-child)::after{display:block}
.state-step-title{font-size:12px;font-weight:700;color:var(--accent);text-transform:uppercase;letter-spacing:.5px;margin-bottom:8px}
.state-step-fields{font-family:'JetBrains Mono',monospace;font-size:11px;color:var(--text-muted);line-height:1.8}
.state-step-fields .changed{color:var(--green);font-weight:600}
.state-step-fields .unchanged{color:var(--text-dim)}

.fade-in{opacity:0;transform:translateY(24px);transition:opacity .6s ease,transform .6s ease}
.fade-in.visible{opacity:1;transform:translateY(0)}

.mobile-toggle{display:none;position:fixed;top:16px;left:16px;z-index:200;width:40px;height:40px;border-radius:var(--radius-sm);background:var(--bg-card);border:1px solid var(--border);cursor:pointer;align-items:center;justify-content:center}
.mobile-toggle span{display:block;width:18px;height:2px;background:var(--text);margin:3px auto;transition:all .2s}

@media(max-width:900px){
  .sidebar{transform:translateX(-100%)}
  .sidebar.open{transform:translateX(0)}
  .main{margin-left:0}
  .mobile-toggle{display:flex}
  .hero{padding:80px 24px 60px}
  .section{padding:40px 24px}
  .metrics{grid-template-columns:1fr 1fr}
  .state-field{flex-direction:column;gap:4px}
  .state-field-name,.state-field-type{min-width:auto}
}
@media(max-width:600px){
  .card-grid{grid-template-columns:1fr}
  .pipeline{flex-wrap:wrap;justify-content:center}
  .metrics{grid-template-columns:1fr}
  .state-timeline{grid-template-columns:1fr}
  .tabs{overflow-x:auto}
}
</style>
</head>
<body>

<button class="mobile-toggle" onclick="document.querySelector('.sidebar').classList.toggle('open')" aria-label="Toggle menu">
  <span></span><span></span><span></span>
</button>

<nav class="sidebar" id="sidebar">
  <div class="sidebar-logo">
    <h2>NeuroWeave</h2>
    <span>Agent Implementation v1.0</span>
  </div>
  <div class="nav-section">
    <div class="nav-section-title">Overview</div>
    <a href="#hero" class="nav-link active"><span class="nav-icon">01</span> Introduction</a>
    <a href="#architecture" class="nav-link"><span class="nav-icon">02</span> Architecture</a>
    <a href="#agent-state" class="nav-link"><span class="nav-icon">03</span> AgentState</a>
  </div>
  <div class="nav-section">
    <div class="nav-section-title">Pipeline Nodes</div>
    <a href="#disentanglement" class="nav-link"><span class="nav-icon">04</span> Disentanglement</a>
    <a href="#router" class="nav-link"><span class="nav-icon">05</span> Router Node</a>
    <a href="#evaluator" class="nav-link"><span class="nav-icon">06</span> Evaluator Node</a>
    <a href="#compiler" class="nav-link"><span class="nav-icon">07</span> Compiler Node</a>
    <a href="#quality-gate" class="nav-link"><span class="nav-icon">08</span> Quality Gate</a>
  </div>
  <div class="nav-section">
    <div class="nav-section-title">Integration</div>
    <a href="#graph-assembly" class="nav-link"><span class="nav-icon">09</span> Graph Assembly</a>
    <a href="#checkpointing" class="nav-link"><span class="nav-icon">10</span> Checkpointing</a>
    <a href="#observability" class="nav-link"><span class="nav-icon">11</span> Observability</a>
    <a href="#celery" class="nav-link"><span class="nav-icon">12</span> Celery Tasks</a>
    <a href="#walkthrough" class="nav-link"><span class="nav-icon">13</span> Data Flow Example</a>
  </div>
</nav>

<main class="main">

<!-- HERO -->
<section class="hero" id="hero">
  <div class="hero-badge"><span class="dot"></span> Implementation Guide</div>
  <h1>
    <span class="gradient">Agent System</span><br>
    Implementation Guide
  </h1>
  <p class="subtitle">
    Deep-dive into the LangGraph multi-agent pipeline &mdash; every node, every state mutation, every LLM call explained with full source code
  </p>
  <div class="metrics">
    <div class="metric"><div class="value">5</div><div class="label">Graph Nodes</div></div>
    <div class="metric"><div class="value">3</div><div class="label">LLM Calls</div></div>
    <div class="metric"><div class="value">Cyclic</div><div class="label">Graph Type</div></div>
    <div class="metric"><div class="value">Pydantic</div><div class="label">Structured Output</div></div>
  </div>
</section>

<!-- SECTION 2: ARCHITECTURE OVERVIEW -->
<section class="section fade-in" id="architecture">
  <div class="section-header">
    <div class="section-number">Section 01</div>
    <h2 class="section-title">Architecture Overview</h2>
    <p class="section-desc">LangGraph StateGraph defining the complete extraction pipeline with conditional edges and cyclic evaluation</p>
  </div>

  <div class="diagram-box">
    <div class="mermaid">
graph TD
    START((START)) --> DISENTANGLE["Disentanglement Engine<br/><i>Sentence-BERT + Clustering</i>"]
    DISENTANGLE --> ROUTER["Router Node<br/><i>Claude Haiku &mdash; Classify</i>"]
    ROUTER -->|NOISE| END_NOISE((END))
    ROUTER -->|TECHNICAL| EVALUATOR["Evaluator Node<br/><i>Claude Haiku &mdash; Assess</i>"]
    EVALUATOR -->|incomplete| CHECKPOINT["Checkpoint<br/><i>Save &amp; Wait</i>"]
    CHECKPOINT -.->|"new messages"| EVALUATOR
    EVALUATOR -->|resolved| COMPILER["Compiler Node<br/><i>Claude Haiku &mdash; Structure</i>"]
    COMPILER --> QUALITY{"Quality Gate<br/><i>Score &ge; 0.7?</i>"}
    QUALITY -->|pass| END_OK((END))
    QUALITY -->|fail + retries &lt; 3| COMPILER
    QUALITY -->|fail + retries &ge; 3| END_REJECT((REJECT))

    style START fill:#22c55e,stroke:#22c55e,color:#000
    style END_NOISE fill:#52525b,stroke:#52525b,color:#e4e4e7
    style END_OK fill:#22c55e,stroke:#22c55e,color:#000
    style END_REJECT fill:#ef4444,stroke:#ef4444,color:#fff
    style DISENTANGLE fill:#1a1a2e,stroke:#06b6d4,color:#e4e4e7
    style ROUTER fill:#1a1a2e,stroke:#6366f1,color:#e4e4e7
    style EVALUATOR fill:#1a1a2e,stroke:#f97316,color:#e4e4e7
    style COMPILER fill:#1a1a2e,stroke:#a855f7,color:#e4e4e7
    style QUALITY fill:#1a1a2e,stroke:#eab308,color:#e4e4e7
    style CHECKPOINT fill:#1a1a2e,stroke:#52525b,color:#e4e4e7
    </div>
  </div>

  <div class="card-grid" style="margin-top:32px">
    <div class="card">
      <div class="card-icon">&#9881;</div>
      <h3>Disentanglement</h3>
      <p class="card-sub">Pre-graph Processing</p>
      <p>Clusters raw Discord messages into logical threads using Sentence-BERT embeddings and cosine similarity</p>
      <div class="tech-tags"><span class="tech-tag">sentence-transformers</span><span class="tech-tag">sklearn</span></div>
    </div>
    <div class="card">
      <div class="card-icon">&#128268;</div>
      <h3>Router</h3>
      <p class="card-sub">LLM Node &mdash; Classification</p>
      <p>Classifies each thread as NOISE or TECHNICAL using Claude Haiku with zero-shot prompting</p>
      <div class="tech-tags"><span class="tech-tag">claude-haiku</span><span class="tech-tag">langchain</span></div>
    </div>
    <div class="card">
      <div class="card-icon">&#128270;</div>
      <h3>Evaluator</h3>
      <p class="card-sub">LLM Node &mdash; Assessment</p>
      <p>Evaluates whether a thread contains a complete, resolved solution. May loop back via checkpoint</p>
      <div class="tech-tags"><span class="tech-tag">cyclic-edge</span><span class="tech-tag">checkpoint</span></div>
    </div>
    <div class="card">
      <div class="card-icon">&#128196;</div>
      <h3>Compiler</h3>
      <p class="card-sub">LLM Node &mdash; Structuring</p>
      <p>Transforms thread into structured JSON via Pydantic schema: symptom, diagnosis, solution, code</p>
      <div class="tech-tags"><span class="tech-tag">pydantic-v2</span><span class="tech-tag">structured-output</span></div>
    </div>
    <div class="card">
      <div class="card-icon">&#9989;</div>
      <h3>Quality Gate</h3>
      <p class="card-sub">Heuristic Scorer</p>
      <p>Non-LLM scoring algorithm: checks solution length, code presence, confidence, tags. Threshold 0.7</p>
      <div class="tech-tags"><span class="tech-tag">heuristic</span><span class="tech-tag">threshold-0.7</span></div>
    </div>
  </div>
</section>

<!-- SECTION 3: AGENT STATE -->
<section class="section fade-in" id="agent-state">
  <div class="section-header">
    <div class="section-number">Section 02</div>
    <h2 class="section-title">AgentState &mdash; State Schema</h2>
    <p class="section-desc">The TypedDict that flows through every node. Each node reads and mutates specific fields</p>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; state.py</span></div>
    <div class="code-body"><span class="kw">from</span> typing <span class="kw">import</span> TypedDict, Literal, Annotated
<span class="kw">from</span> langchain_core.messages <span class="kw">import</span> BaseMessage
<span class="kw">import</span> operator


<span class="kw">class</span> <span class="tp">ThreadMessage</span>(TypedDict):
    <span class="str">"""Single message within a disentangled thread."""</span>
    author_hash: <span class="tp">str</span>           <span class="cm"># SHA-256 of Discord user ID</span>
    content: <span class="tp">str</span>               <span class="cm"># PII-redacted message text</span>
    timestamp: <span class="tp">str</span>             <span class="cm"># ISO 8601 timestamp</span>
    has_code: <span class="tp">bool</span>             <span class="cm"># Contains code block?</span>
    has_mention: <span class="tp">bool</span>          <span class="cm"># Contains @mention?</span>


<span class="kw">class</span> <span class="tp">EvaluationResult</span>(TypedDict):
    <span class="str">"""Evaluator node output."""</span>
    has_solution: <span class="tp">bool</span>         <span class="cm"># Thread contains a proposed solution</span>
    has_code: <span class="tp">bool</span>             <span class="cm"># Solution includes code snippet</span>
    is_resolved: <span class="tp">bool</span>          <span class="cm"># Problem was confirmed resolved</span>
    reasoning: <span class="tp">str</span>             <span class="cm"># LLM's evaluation reasoning</span>


<span class="kw">class</span> <span class="tp">CompiledArticle</span>(TypedDict):
    <span class="str">"""Compiler node structured output."""</span>
    symptom: <span class="tp">str</span>
    diagnosis: <span class="tp">str</span>
    solution: <span class="tp">str</span>
    code_snippet: <span class="tp">str</span> | <span class="tp">None</span>
    language: <span class="tp">str</span>
    framework: <span class="tp">str</span> | <span class="tp">None</span>
    tags: <span class="tp">list</span>[<span class="tp">str</span>]
    confidence: <span class="tp">float</span>
    thread_summary: <span class="tp">str</span>


<span class="kw">class</span> <span class="tp">AgentState</span>(TypedDict):
    <span class="str">"""Main state schema flowing through the LangGraph pipeline."""</span>

    <span class="cm"># --- Input ---</span>
    messages: Annotated[<span class="tp">list</span>[BaseMessage], operator.add]
    threads: <span class="tp">list</span>[<span class="tp">list</span>[ThreadMessage]]

    <span class="cm"># --- Router output ---</span>
    classification: Literal[<span class="str">"NOISE"</span>, <span class="str">"TECHNICAL"</span>, <span class="str">""</span>]

    <span class="cm"># --- Evaluator output ---</span>
    evaluation: EvaluationResult | <span class="tp">None</span>

    <span class="cm"># --- Compiler output ---</span>
    compiled_article: CompiledArticle | <span class="tp">None</span>

    <span class="cm"># --- Quality gate ---</span>
    quality_score: <span class="tp">float</span>
    retry_count: <span class="tp">int</span>

    <span class="cm"># --- Metadata ---</span>
    current_thread_idx: <span class="tp">int</span>
    server_id: <span class="tp">str</span>
    channel_id: <span class="tp">str</span>
    error: <span class="tp">str</span> | <span class="tp">None</span></div>
  </div>

  <h3 style="font-size:18px;font-weight:600;margin:32px 0 16px">State Mutation Flow</h3>
  <p style="color:var(--text-muted);font-size:14px;margin-bottom:20px">How the state evolves as it passes through each node. <span style="color:var(--green)">Green</span> = mutated fields at each step.</p>

  <div class="state-timeline">
    <div class="state-step">
      <div class="state-step-title">&#9312; Input</div>
      <div class="state-step-fields">
        <div class="changed">messages: [...]</div>
        <div class="changed">threads: []</div>
        <div class="unchanged">classification: ""</div>
        <div class="unchanged">evaluation: null</div>
        <div class="unchanged">compiled_article: null</div>
        <div class="unchanged">quality_score: 0.0</div>
        <div class="unchanged">retry_count: 0</div>
      </div>
    </div>
    <div class="state-step">
      <div class="state-step-title">&#9313; Disentangle</div>
      <div class="state-step-fields">
        <div class="unchanged">messages: [...]</div>
        <div class="changed">threads: [[msg,msg],[msg]]</div>
        <div class="unchanged">classification: ""</div>
        <div class="unchanged">evaluation: null</div>
        <div class="unchanged">compiled_article: null</div>
        <div class="unchanged">quality_score: 0.0</div>
        <div class="unchanged">retry_count: 0</div>
      </div>
    </div>
    <div class="state-step">
      <div class="state-step-title">&#9314; Router</div>
      <div class="state-step-fields">
        <div class="unchanged">messages: [...]</div>
        <div class="unchanged">threads: [[msg,...]]</div>
        <div class="changed">classification: "TECHNICAL"</div>
        <div class="unchanged">evaluation: null</div>
        <div class="unchanged">compiled_article: null</div>
        <div class="unchanged">quality_score: 0.0</div>
        <div class="unchanged">retry_count: 0</div>
      </div>
    </div>
    <div class="state-step">
      <div class="state-step-title">&#9315; Evaluator</div>
      <div class="state-step-fields">
        <div class="unchanged">messages: [...]</div>
        <div class="unchanged">threads: [[msg,...]]</div>
        <div class="unchanged">classification: "TECHNICAL"</div>
        <div class="changed">evaluation: {resolved:true}</div>
        <div class="unchanged">compiled_article: null</div>
        <div class="unchanged">quality_score: 0.0</div>
        <div class="unchanged">retry_count: 0</div>
      </div>
    </div>
    <div class="state-step">
      <div class="state-step-title">&#9316; Compiler</div>
      <div class="state-step-fields">
        <div class="unchanged">messages: [...]</div>
        <div class="unchanged">threads: [[msg,...]]</div>
        <div class="unchanged">classification: "TECHNICAL"</div>
        <div class="unchanged">evaluation: {resolved:true}</div>
        <div class="changed">compiled_article: {...}</div>
        <div class="unchanged">quality_score: 0.0</div>
        <div class="unchanged">retry_count: 0</div>
      </div>
    </div>
    <div class="state-step">
      <div class="state-step-title">&#9317; Quality Gate</div>
      <div class="state-step-fields">
        <div class="unchanged">messages: [...]</div>
        <div class="unchanged">threads: [[msg,...]]</div>
        <div class="unchanged">classification: "TECHNICAL"</div>
        <div class="unchanged">evaluation: {resolved:true}</div>
        <div class="unchanged">compiled_article: {...}</div>
        <div class="changed">quality_score: 0.87</div>
        <div class="changed">retry_count: 0</div>
      </div>
    </div>
  </div>
</section>

<!-- SECTION 4: DISENTANGLEMENT -->
<section class="section fade-in" id="disentanglement">
  <div class="section-header">
    <div class="section-number">Section 03</div>
    <h2 class="section-title">Disentanglement Engine</h2>
    <p class="section-desc">Pre-graph step: Discord channels are chaotic. Multiple conversations happen simultaneously. We cluster messages into logical threads</p>
  </div>

  <div class="diagram-box">
    <div class="mermaid">
graph LR
    RAW["Raw Messages<br/><i>Chronological stream</i>"] --> EMB["Sentence-BERT<br/><i>384-dim embeddings</i>"]
    EMB --> SIM["Cosine Similarity<br/><i>Pairwise matrix</i>"]
    SIM --> CLUSTER["Temporal Clustering<br/><i>threshold &gt; 0.75</i>"]
    CLUSTER --> THREADS["Logical Threads<br/><i>Grouped messages</i>"]

    style RAW fill:#1a1a2e,stroke:#ef4444,color:#e4e4e7
    style EMB fill:#1a1a2e,stroke:#6366f1,color:#e4e4e7
    style SIM fill:#1a1a2e,stroke:#f97316,color:#e4e4e7
    style CLUSTER fill:#1a1a2e,stroke:#a855f7,color:#e4e4e7
    style THREADS fill:#1a1a2e,stroke:#22c55e,color:#e4e4e7
    </div>
  </div>

  <div class="card" style="margin:24px 0;padding:20px 24px">
    <h3 style="font-size:15px;margin-bottom:12px">Algorithm Details</h3>
    <ul style="font-size:13px;color:var(--text-muted);line-height:1.8;margin-left:16px">
      <li><strong style="color:var(--text)">Embedding:</strong> all-MiniLM-L6-v2 generates 384-dim vectors per message</li>
      <li><strong style="color:var(--text)">Similarity:</strong> Pairwise cosine similarity matrix across all messages in batch</li>
      <li><strong style="color:var(--text)">Threshold:</strong> Messages with similarity &gt; 0.75 are candidates for same thread</li>
      <li><strong style="color:var(--text)">Temporal window:</strong> Only messages within 4-hour window can be in same thread</li>
      <li><strong style="color:var(--text)">@mention detection:</strong> Direct replies and @mentions force-link messages regardless of similarity</li>
      <li><strong style="color:var(--text)">Quote references:</strong> Discord reply-quotes are treated as explicit thread links</li>
    </ul>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; disentanglement.py</span></div>
    <div class="code-body"><span class="kw">from</span> sentence_transformers <span class="kw">import</span> SentenceTransformer
<span class="kw">from</span> sklearn.metrics.pairwise <span class="kw">import</span> cosine_similarity
<span class="kw">from</span> datetime <span class="kw">import</span> datetime, timedelta
<span class="kw">import</span> numpy <span class="kw">as</span> np
<span class="kw">from</span> dataclasses <span class="kw">import</span> dataclass


<span class="nb">@dataclass</span>
<span class="kw">class</span> <span class="tp">RawMessage</span>:
    id: <span class="tp">str</span>
    author_hash: <span class="tp">str</span>
    content: <span class="tp">str</span>
    timestamp: datetime
    reply_to: <span class="tp">str</span> | <span class="tp">None</span> = <span class="tp">None</span>
    mentions: <span class="tp">list</span>[<span class="tp">str</span>] = <span class="tp">None</span>


<span class="kw">class</span> <span class="tp">DisentanglementEngine</span>:
    <span class="str">"""Clusters raw Discord messages into logical conversation threads."""</span>

    SIMILARITY_THRESHOLD = <span class="num">0.75</span>
    TEMPORAL_WINDOW = timedelta(hours=<span class="num">4</span>)

    <span class="kw">def</span> <span class="fn">__init__</span>(self):
        self.model = SentenceTransformer(<span class="str">"all-MiniLM-L6-v2"</span>)

    <span class="kw">def</span> <span class="fn">cluster</span>(self, messages: <span class="tp">list</span>[RawMessage]) -> <span class="tp">list</span>[<span class="tp">list</span>[RawMessage]]:
        <span class="str">"""Main entry: takes raw messages, returns grouped threads."""</span>
        <span class="kw">if not</span> messages:
            <span class="kw">return</span> []

        <span class="cm"># Step 1: Generate embeddings for all messages</span>
        texts = [m.content <span class="kw">for</span> m <span class="kw">in</span> messages]
        embeddings = self.model.encode(texts, show_progress_bar=<span class="kw">False</span>)

        <span class="cm"># Step 2: Compute pairwise cosine similarity matrix</span>
        sim_matrix = cosine_similarity(embeddings)

        <span class="cm"># Step 3: Build adjacency via similarity + temporal + explicit links</span>
        n = len(messages)
        adjacency = np.zeros((n, n), dtype=<span class="tp">bool</span>)

        <span class="kw">for</span> i <span class="kw">in</span> range(n):
            <span class="kw">for</span> j <span class="kw">in</span> range(i + <span class="num">1</span>, n):
                time_ok = (
                    abs(messages[i].timestamp - messages[j].timestamp)
                    &lt;= self.TEMPORAL_WINDOW
                )
                <span class="kw">if not</span> time_ok:
                    <span class="kw">continue</span>

                <span class="cm"># Explicit links: reply-to or @mention</span>
                explicit = (
                    messages[j].reply_to == messages[i].id
                    <span class="kw">or</span> (messages[j].mentions <span class="kw">and</span>
                        messages[i].author_hash <span class="kw">in</span> messages[j].mentions)
                )
                <span class="kw">if</span> explicit <span class="kw">or</span> sim_matrix[i][j] >= self.SIMILARITY_THRESHOLD:
                    adjacency[i][j] = <span class="kw">True</span>
                    adjacency[j][i] = <span class="kw">True</span>

        <span class="cm"># Step 4: Connected components via BFS</span>
        visited = set()
        threads = []

        <span class="kw">for</span> start <span class="kw">in</span> range(n):
            <span class="kw">if</span> start <span class="kw">in</span> visited:
                <span class="kw">continue</span>
            queue = [start]
            component = []
            <span class="kw">while</span> queue:
                node = queue.pop(<span class="num">0</span>)
                <span class="kw">if</span> node <span class="kw">in</span> visited:
                    <span class="kw">continue</span>
                visited.add(node)
                component.append(node)
                <span class="kw">for</span> neighbor <span class="kw">in</span> range(n):
                    <span class="kw">if</span> adjacency[node][neighbor] <span class="kw">and</span> neighbor <span class="kw">not in</span> visited:
                        queue.append(neighbor)

            <span class="cm"># Sort by timestamp within thread</span>
            component.sort(key=<span class="kw">lambda</span> idx: messages[idx].timestamp)
            threads.append([messages[idx] <span class="kw">for</span> idx <span class="kw">in</span> component])

        <span class="kw">return</span> threads</div>
  </div>
</section>

<!-- SECTION 5: ROUTER NODE -->
<section class="section fade-in" id="router">
  <div class="section-header">
    <div class="section-number">Section 04</div>
    <h2 class="section-title">Router Node</h2>
    <p class="section-desc">Classifies each thread as NOISE or TECHNICAL using Claude Haiku with zero-shot prompting</p>
  </div>

  <div style="display:grid;grid-template-columns:1fr 1fr;gap:20px;margin-bottom:32px">
    <div class="card" style="border-left:3px solid var(--red)">
      <h3 style="color:var(--red)">NOISE Criteria</h3>
      <ul style="font-size:13px;color:var(--text-muted);line-height:1.8;margin-left:16px;margin-top:8px">
        <li>Greetings, small talk, off-topic chat</li>
        <li>Memes, jokes, emoji-only messages</li>
        <li>Bot commands unrelated to tech support</li>
        <li>Self-promotion, spam, link drops</li>
        <li>&lt;3 messages with no technical content</li>
      </ul>
    </div>
    <div class="card" style="border-left:3px solid var(--green)">
      <h3 style="color:var(--green)">TECHNICAL Criteria</h3>
      <ul style="font-size:13px;color:var(--text-muted);line-height:1.8;margin-left:16px;margin-top:8px">
        <li>Question + discussion about code</li>
        <li>Stack traces, error messages, logs</li>
        <li>Configuration files, CLI commands</li>
        <li>Architecture or design discussions</li>
        <li>Bug reports with reproduction steps</li>
      </ul>
    </div>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; nodes/router.py</span></div>
    <div class="code-body"><span class="kw">from</span> langchain_anthropic <span class="kw">import</span> ChatAnthropic
<span class="kw">from</span> langchain_core.messages <span class="kw">import</span> SystemMessage, HumanMessage
<span class="kw">from</span> state <span class="kw">import</span> AgentState


ROUTER_SYSTEM_PROMPT = <span class="str">"""You are a Discord message classifier for a technical community.

Your job: classify a conversation thread as either NOISE or TECHNICAL.

NOISE = greetings, memes, off-topic chat, emoji spam, bot commands,
        self-promotion, messages with no technical substance.

TECHNICAL = questions about code, error messages, stack traces,
            configuration issues, architecture discussions,
            bug reports, code reviews, deployment problems.

Rules:
- If the thread has fewer than 3 messages AND no code/errors, lean NOISE
- If ANY message contains a stack trace or code block, lean TECHNICAL
- When uncertain, classify as TECHNICAL (false positives are cheaper)

Respond with exactly one word: NOISE or TECHNICAL"""</span>


llm = ChatAnthropic(model=<span class="str">"claude-haiku-4-5-20251001"</span>, temperature=<span class="num">0</span>)


<span class="kw">def</span> <span class="fn">router_node</span>(state: AgentState) -> <span class="tp">dict</span>:
    <span class="str">"""Classify the current thread as NOISE or TECHNICAL."""</span>
    thread = state[<span class="str">"threads"</span>][state[<span class="str">"current_thread_idx"</span>]]

    <span class="cm"># Format thread for LLM</span>
    formatted = <span class="str">"\n"</span>.join(
        <span class="str">f"[{m['timestamp']}] {m['author_hash'][:8]}: {m['content']}"</span>
        <span class="kw">for</span> m <span class="kw">in</span> thread
    )

    response = llm.invoke([
        SystemMessage(content=ROUTER_SYSTEM_PROMPT),
        HumanMessage(content=<span class="str">f"Classify this thread:\n\n{formatted}"</span>),
    ])

    classification = response.content.strip().upper()
    <span class="kw">if</span> classification <span class="kw">not in</span> (<span class="str">"NOISE"</span>, <span class="str">"TECHNICAL"</span>):
        classification = <span class="str">"TECHNICAL"</span>  <span class="cm"># Default: false positive is cheaper</span>

    <span class="kw">return</span> {<span class="str">"classification"</span>: classification}


<span class="kw">def</span> <span class="fn">route_after_classification</span>(state: AgentState) -> <span class="tp">str</span>:
    <span class="str">"""Conditional edge: decide next node based on classification."""</span>
    <span class="kw">if</span> state[<span class="str">"classification"</span>] == <span class="str">"NOISE"</span>:
        <span class="kw">return</span> <span class="str">"__end__"</span>
    <span class="kw">return</span> <span class="str">"evaluator"</span></div>
  </div>
</section>

<!-- SECTION 6: EVALUATOR NODE -->
<section class="section fade-in" id="evaluator">
  <div class="section-header">
    <div class="section-number">Section 05</div>
    <h2 class="section-title">Evaluator Node</h2>
    <p class="section-desc">Assesses whether a technical thread contains a complete, resolved solution. Supports cyclic re-evaluation</p>
  </div>

  <div class="diagram-box">
    <div class="mermaid">
graph LR
    EVAL["Evaluator<br/>LLM Analysis"] -->|"is_resolved=true"| COMPILE["Compiler Node"]
    EVAL -->|"is_resolved=false"| CP["Checkpoint<br/>Save State"]
    CP -->|"New messages arrive"| EVAL
    CP -->|"Timeout (24h)"| DISCARD["Discard Thread"]

    style EVAL fill:#1a1a2e,stroke:#f97316,color:#e4e4e7
    style COMPILE fill:#1a1a2e,stroke:#a855f7,color:#e4e4e7
    style CP fill:#1a1a2e,stroke:#52525b,color:#e4e4e7
    style DISCARD fill:#1a1a2e,stroke:#ef4444,color:#e4e4e7
    </div>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; nodes/evaluator.py</span></div>
    <div class="code-body"><span class="kw">from</span> langchain_anthropic <span class="kw">import</span> ChatAnthropic
<span class="kw">from</span> langchain_core.messages <span class="kw">import</span> SystemMessage, HumanMessage
<span class="kw">import</span> json
<span class="kw">from</span> state <span class="kw">import</span> AgentState, EvaluationResult


EVALUATOR_SYSTEM_PROMPT = <span class="str">"""You are evaluating a technical Discord conversation thread.

Analyze the thread and determine:
1. has_solution: Does anyone propose a concrete solution?
2. has_code: Is there a code snippet, config change, or CLI command?
3. is_resolved: Did the original poster confirm it works, or is the
   solution clearly correct based on the discussion?

Respond in JSON format:
{
  "has_solution": true/false,
  "has_code": true/false,
  "is_resolved": true/false,
  "reasoning": "Brief explanation of your assessment"
}

Be conservative with is_resolved: only mark true if there's clear
evidence the problem was actually solved."""</span>


llm = ChatAnthropic(model=<span class="str">"claude-haiku-4-5-20251001"</span>, temperature=<span class="num">0</span>)


<span class="kw">def</span> <span class="fn">evaluator_node</span>(state: AgentState) -> <span class="tp">dict</span>:
    <span class="str">"""Evaluate whether the thread has a complete resolution."""</span>
    thread = state[<span class="str">"threads"</span>][state[<span class="str">"current_thread_idx"</span>]]

    formatted = <span class="str">"\n"</span>.join(
        <span class="str">f"[{m['timestamp']}] {m['author_hash'][:8]}: {m['content']}"</span>
        <span class="kw">for</span> m <span class="kw">in</span> thread
    )

    response = llm.invoke([
        SystemMessage(content=EVALUATOR_SYSTEM_PROMPT),
        HumanMessage(content=<span class="str">f"Evaluate this thread:\n\n{formatted}"</span>),
    ])

    <span class="kw">try</span>:
        result = json.loads(response.content)
        evaluation: EvaluationResult = {
            <span class="str">"has_solution"</span>: result.get(<span class="str">"has_solution"</span>, <span class="kw">False</span>),
            <span class="str">"has_code"</span>: result.get(<span class="str">"has_code"</span>, <span class="kw">False</span>),
            <span class="str">"is_resolved"</span>: result.get(<span class="str">"is_resolved"</span>, <span class="kw">False</span>),
            <span class="str">"reasoning"</span>: result.get(<span class="str">"reasoning"</span>, <span class="str">""</span>),
        }
    <span class="kw">except</span> (json.JSONDecodeError, KeyError):
        evaluation: EvaluationResult = {
            <span class="str">"has_solution"</span>: <span class="kw">False</span>,
            <span class="str">"has_code"</span>: <span class="kw">False</span>,
            <span class="str">"is_resolved"</span>: <span class="kw">False</span>,
            <span class="str">"reasoning"</span>: <span class="str">"Failed to parse LLM response"</span>,
        }

    <span class="kw">return</span> {<span class="str">"evaluation"</span>: evaluation}


<span class="kw">def</span> <span class="fn">route_after_evaluation</span>(state: AgentState) -> <span class="tp">str</span>:
    <span class="str">"""Conditional edge: resolved threads go to compiler, others checkpoint."""</span>
    evaluation = state.get(<span class="str">"evaluation"</span>)
    <span class="kw">if</span> evaluation <span class="kw">and</span> evaluation[<span class="str">"is_resolved"</span>]:
        <span class="kw">return</span> <span class="str">"compiler"</span>
    <span class="cm"># Not resolved: save checkpoint, wait for new messages</span>
    <span class="kw">return</span> <span class="str">"__end__"</span>  <span class="cm"># Graph ends; checkpoint persists state</span></div>
  </div>

  <div class="card" style="margin-top:24px;padding:20px 24px">
    <h3 style="font-size:15px;margin-bottom:10px">Cyclic Re-evaluation Flow</h3>
    <ol style="font-size:13px;color:var(--text-muted);line-height:1.8;padding-left:18px">
      <li>Thread enters evaluator &rarr; <code>is_resolved: false</code></li>
      <li>Graph ends with checkpoint &mdash; state is persisted (MongoDB / Memory)</li>
      <li>New messages arrive in the same Discord channel</li>
      <li>Celery task detects messages belong to an existing checkpointed thread</li>
      <li>Graph is <strong>resumed from checkpoint</strong> with updated <code>threads</code> field</li>
      <li>Evaluator re-runs with the new messages included</li>
      <li>If <code>is_resolved: true</code> now &rarr; proceeds to Compiler</li>
      <li>After 24h without resolution &rarr; thread is discarded</li>
    </ol>
  </div>
</section>

<!-- SECTION 7: COMPILER NODE -->
<section class="section fade-in" id="compiler">
  <div class="section-header">
    <div class="section-number">Section 06</div>
    <h2 class="section-title">Compiler Node</h2>
    <p class="section-desc">Transforms a resolved thread into structured JSON using Claude Haiku with Pydantic schema enforcement via <code>with_structured_output()</code></p>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; nodes/compiler.py</span></div>
    <div class="code-body"><span class="kw">from</span> langchain_anthropic <span class="kw">import</span> ChatAnthropic
<span class="kw">from</span> langchain_core.messages <span class="kw">import</span> SystemMessage, HumanMessage
<span class="kw">from</span> pydantic <span class="kw">import</span> BaseModel, Field
<span class="kw">from</span> state <span class="kw">import</span> AgentState


<span class="kw">class</span> <span class="tp">ExtractedKnowledge</span>(BaseModel):
    <span class="str">"""Pydantic schema for structured knowledge extraction."""</span>

    symptom: <span class="tp">str</span> = Field(
        description=<span class="str">"The problem or error the user encountered"</span>
    )
    diagnosis: <span class="tp">str</span> = Field(
        description=<span class="str">"Root cause analysis of the problem"</span>
    )
    solution: <span class="tp">str</span> = Field(
        description=<span class="str">"Step-by-step solution that resolved the issue"</span>
    )
    code_snippet: <span class="tp">str</span> | <span class="tp">None</span> = Field(
        default=<span class="tp">None</span>,
        description=<span class="str">"Relevant code fix, config change, or CLI command"</span>
    )
    language: <span class="tp">str</span> = Field(
        description=<span class="str">"Primary programming language (python, javascript, rust, etc.)"</span>
    )
    framework: <span class="tp">str</span> | <span class="tp">None</span> = Field(
        default=<span class="tp">None</span>,
        description=<span class="str">"Framework if applicable (Next.js, Django, Tokio, etc.)"</span>
    )
    tags: <span class="tp">list</span>[<span class="tp">str</span>] = Field(
        description=<span class="str">"3-7 relevant tags for search/filtering"</span>
    )
    confidence: <span class="tp">float</span> = Field(
        ge=<span class="num">0.0</span>, le=<span class="num">1.0</span>,
        description=<span class="str">"Confidence in the extracted knowledge (0.0-1.0)"</span>
    )
    thread_summary: <span class="tp">str</span> = Field(
        description=<span class="str">"One-line summary for search results"</span>
    )


COMPILER_SYSTEM_PROMPT = <span class="str">"""You are a technical knowledge compiler.

Given a Discord conversation thread where a technical problem was discussed
and resolved, extract structured knowledge.

Focus on:
- Clearly stating the SYMPTOM (what went wrong)
- Identifying the DIAGNOSIS (why it went wrong)
- Providing a concrete SOLUTION (how to fix it)
- Including any CODE SNIPPET that was part of the fix
- Assigning relevant TAGS for discoverability

Be precise. Use the actual technical details from the conversation.
Do not hallucinate solutions that weren't discussed."""</span>


llm = ChatAnthropic(
    model=<span class="str">"claude-haiku-4-5-20251001"</span>,
    temperature=<span class="num">0</span>,
)

<span class="cm"># Bind Pydantic schema for structured output</span>
structured_llm = llm.with_structured_output(ExtractedKnowledge)


<span class="kw">def</span> <span class="fn">compiler_node</span>(state: AgentState) -> <span class="tp">dict</span>:
    <span class="str">"""Compile thread into structured ExtractedKnowledge."""</span>
    thread = state[<span class="str">"threads"</span>][state[<span class="str">"current_thread_idx"</span>]]

    formatted = <span class="str">"\n"</span>.join(
        <span class="str">f"[{m['timestamp']}] {m['author_hash'][:8]}: {m['content']}"</span>
        <span class="kw">for</span> m <span class="kw">in</span> thread
    )

    <span class="kw">try</span>:
        result: ExtractedKnowledge = structured_llm.invoke([
            SystemMessage(content=COMPILER_SYSTEM_PROMPT),
            HumanMessage(content=<span class="str">f"Compile this thread:\n\n{formatted}"</span>),
        ])
        compiled = result.model_dump()
    <span class="kw">except</span> Exception <span class="kw">as</span> e:
        <span class="cm"># Validation error or LLM failure: return empty for retry</span>
        compiled = <span class="tp">None</span>

    <span class="kw">return</span> {<span class="str">"compiled_article"</span>: compiled}</div>
  </div>

  <div class="card" style="margin-top:24px;padding:20px 24px">
    <h3 style="font-size:15px;margin-bottom:10px"><code>with_structured_output()</code> &mdash; How It Works</h3>
    <ol style="font-size:13px;color:var(--text-muted);line-height:1.8;padding-left:18px">
      <li>LangChain converts the Pydantic schema to a JSON schema</li>
      <li>Schema is passed to Claude's <code>tool_use</code> API as a tool definition</li>
      <li>Claude generates a tool call with structured JSON matching the schema</li>
      <li>LangChain parses the tool call result back into a Pydantic instance</li>
      <li>Pydantic validates all fields (types, ranges, required fields)</li>
      <li>If validation fails &rarr; retry with error feedback (up to 3 attempts)</li>
    </ol>
  </div>
</section>

<!-- SECTION 8: QUALITY GATE -->
<section class="section fade-in" id="quality-gate">
  <div class="section-header">
    <div class="section-number">Section 07</div>
    <h2 class="section-title">Quality Gate</h2>
    <p class="section-desc">Heuristic scoring algorithm (no LLM) that validates compiled articles. Score must exceed 0.7 threshold</p>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; nodes/quality_gate.py</span></div>
    <div class="code-body"><span class="kw">from</span> state <span class="kw">import</span> AgentState


QUALITY_THRESHOLD = <span class="num">0.7</span>
MAX_RETRIES = <span class="num">3</span>


<span class="kw">def</span> <span class="fn">compute_quality_score</span>(article: <span class="tp">dict</span>) -> <span class="tp">float</span>:
    <span class="str">"""Heuristic quality scorer. Returns 0.0 - 1.0."""</span>
    <span class="kw">if not</span> article:
        <span class="kw">return</span> <span class="num">0.0</span>

    score = <span class="num">0.0</span>

    <span class="cm"># Factor 1: Solution length (max 0.25)</span>
    sol_len = len(article.get(<span class="str">"solution"</span>, <span class="str">""</span>))
    <span class="kw">if</span> sol_len > <span class="num">200</span>:
        score += <span class="num">0.25</span>
    <span class="kw">elif</span> sol_len > <span class="num">100</span>:
        score += <span class="num">0.15</span>
    <span class="kw">elif</span> sol_len > <span class="num">50</span>:
        score += <span class="num">0.08</span>

    <span class="cm"># Factor 2: Code snippet present (max 0.20)</span>
    <span class="kw">if</span> article.get(<span class="str">"code_snippet"</span>):
        snippet_len = len(article[<span class="str">"code_snippet"</span>])
        <span class="kw">if</span> snippet_len > <span class="num">50</span>:
            score += <span class="num">0.20</span>
        <span class="kw">else</span>:
            score += <span class="num">0.10</span>

    <span class="cm"># Factor 3: Confidence from LLM (max 0.20)</span>
    confidence = article.get(<span class="str">"confidence"</span>, <span class="num">0.0</span>)
    score += min(confidence * <span class="num">0.20</span>, <span class="num">0.20</span>)

    <span class="cm"># Factor 4: Tags coverage (max 0.15)</span>
    tags = article.get(<span class="str">"tags"</span>, [])
    <span class="kw">if</span> len(tags) >= <span class="num">5</span>:
        score += <span class="num">0.15</span>
    <span class="kw">elif</span> len(tags) >= <span class="num">3</span>:
        score += <span class="num">0.10</span>
    <span class="kw">elif</span> len(tags) >= <span class="num">1</span>:
        score += <span class="num">0.05</span>

    <span class="cm"># Factor 5: Diagnosis present and meaningful (max 0.10)</span>
    diag = article.get(<span class="str">"diagnosis"</span>, <span class="str">""</span>)
    <span class="kw">if</span> len(diag) > <span class="num">80</span>:
        score += <span class="num">0.10</span>
    <span class="kw">elif</span> len(diag) > <span class="num">30</span>:
        score += <span class="num">0.05</span>

    <span class="cm"># Factor 6: Thread summary exists (max 0.10)</span>
    <span class="kw">if</span> len(article.get(<span class="str">"thread_summary"</span>, <span class="str">""</span>)) > <span class="num">10</span>:
        score += <span class="num">0.10</span>

    <span class="kw">return</span> round(min(score, <span class="num">1.0</span>), <span class="num">2</span>)


<span class="kw">def</span> <span class="fn">quality_gate_node</span>(state: AgentState) -> <span class="tp">dict</span>:
    <span class="str">"""Score the compiled article and update state."""</span>
    article = state.get(<span class="str">"compiled_article"</span>)
    score = compute_quality_score(article)
    retry_count = state.get(<span class="str">"retry_count"</span>, <span class="num">0</span>)

    <span class="kw">return</span> {
        <span class="str">"quality_score"</span>: score,
        <span class="str">"retry_count"</span>: retry_count + (<span class="num">1</span> <span class="kw">if</span> score &lt; QUALITY_THRESHOLD <span class="kw">else</span> <span class="num">0</span>),
    }


<span class="kw">def</span> <span class="fn">route_after_quality</span>(state: AgentState) -> <span class="tp">str</span>:
    <span class="str">"""Conditional edge: pass, retry compiler, or reject."""</span>
    <span class="kw">if</span> state[<span class="str">"quality_score"</span>] >= QUALITY_THRESHOLD:
        <span class="kw">return</span> <span class="str">"__end__"</span>  <span class="cm"># Pass: store article</span>
    <span class="kw">if</span> state[<span class="str">"retry_count"</span>] &lt; MAX_RETRIES:
        <span class="kw">return</span> <span class="str">"compiler"</span>  <span class="cm"># Retry: re-compile</span>
    <span class="kw">return</span> <span class="str">"__end__"</span>  <span class="cm"># Reject: too many retries</span></div>
  </div>

  <div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(120px,1fr));gap:12px;margin-top:24px">
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--accent-hover)">0.25</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">Solution Length</div>
    </div>
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--green)">0.20</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">Code Present</div>
    </div>
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--cyan)">0.20</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">LLM Confidence</div>
    </div>
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--orange)">0.15</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">Tags Coverage</div>
    </div>
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--purple)">0.10</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">Diagnosis</div>
    </div>
    <div class="card" style="padding:16px;text-align:center">
      <div style="font-size:24px;font-weight:700;color:var(--pink)">0.10</div>
      <div style="font-size:11px;color:var(--text-muted);margin-top:4px">Summary</div>
    </div>
  </div>
</section>

<!-- SECTION 9: GRAPH ASSEMBLY -->
<section class="section fade-in" id="graph-assembly">
  <div class="section-header">
    <div class="section-number">Section 08</div>
    <h2 class="section-title">Graph Assembly &mdash; <code>graph.py</code></h2>
    <p class="section-desc">Full LangGraph StateGraph construction: nodes, edges, conditional routing, and compilation with checkpointer</p>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; graph.py</span></div>
    <div class="code-body"><span class="kw">from</span> langgraph.graph <span class="kw">import</span> StateGraph, END
<span class="kw">from</span> langgraph.checkpoint.mongodb <span class="kw">import</span> MongoDBSaver
<span class="kw">from</span> langgraph.checkpoint.memory <span class="kw">import</span> MemorySaver

<span class="kw">from</span> state <span class="kw">import</span> AgentState
<span class="kw">from</span> disentanglement <span class="kw">import</span> DisentanglementEngine
<span class="kw">from</span> nodes.router <span class="kw">import</span> router_node, route_after_classification
<span class="kw">from</span> nodes.evaluator <span class="kw">import</span> evaluator_node, route_after_evaluation
<span class="kw">from</span> nodes.compiler <span class="kw">import</span> compiler_node
<span class="kw">from</span> nodes.quality_gate <span class="kw">import</span> quality_gate_node, route_after_quality

<span class="kw">import</span> os


<span class="cm"># --- Pre-graph processor ---</span>
disentangle = DisentanglementEngine()

<span class="kw">def</span> <span class="fn">disentangle_node</span>(state: AgentState) -> <span class="tp">dict</span>:
    <span class="str">"""Cluster raw messages into threads."""</span>
    raw_msgs = state[<span class="str">"messages"</span>]
    threads = disentangle.cluster(raw_msgs)
    <span class="kw">return</span> {
        <span class="str">"threads"</span>: [[
            {
                <span class="str">"author_hash"</span>: m.author_hash,
                <span class="str">"content"</span>: m.content,
                <span class="str">"timestamp"</span>: m.timestamp.isoformat(),
                <span class="str">"has_code"</span>: <span class="str">"```"</span> <span class="kw">in</span> m.content,
                <span class="str">"has_mention"</span>: <span class="str">"@"</span> <span class="kw">in</span> m.content,
            }
            <span class="kw">for</span> m <span class="kw">in</span> thread
        ] <span class="kw">for</span> thread <span class="kw">in</span> threads],
        <span class="str">"current_thread_idx"</span>: <span class="num">0</span>,
    }


<span class="cm"># --- Build the graph ---</span>
<span class="kw">def</span> <span class="fn">build_graph</span>(use_mongodb: <span class="tp">bool</span> = <span class="kw">False</span>):
    <span class="str">"""Construct and compile the extraction pipeline graph."""</span>

    <span class="cm"># 1. Initialize StateGraph with schema</span>
    workflow = StateGraph(AgentState)

    <span class="cm"># 2. Add nodes</span>
    workflow.add_node(<span class="str">"disentangle"</span>, disentangle_node)
    workflow.add_node(<span class="str">"router"</span>, router_node)
    workflow.add_node(<span class="str">"evaluator"</span>, evaluator_node)
    workflow.add_node(<span class="str">"compiler"</span>, compiler_node)
    workflow.add_node(<span class="str">"quality_gate"</span>, quality_gate_node)

    <span class="cm"># 3. Set entry point</span>
    workflow.set_entry_point(<span class="str">"disentangle"</span>)

    <span class="cm"># 4. Add edges</span>
    workflow.add_edge(<span class="str">"disentangle"</span>, <span class="str">"router"</span>)

    <span class="cm"># 5. Conditional edges</span>
    workflow.add_conditional_edges(
        <span class="str">"router"</span>,
        route_after_classification,
        {<span class="str">"evaluator"</span>: <span class="str">"evaluator"</span>, <span class="str">"__end__"</span>: END},
    )
    workflow.add_conditional_edges(
        <span class="str">"evaluator"</span>,
        route_after_evaluation,
        {<span class="str">"compiler"</span>: <span class="str">"compiler"</span>, <span class="str">"__end__"</span>: END},
    )

    workflow.add_edge(<span class="str">"compiler"</span>, <span class="str">"quality_gate"</span>)

    workflow.add_conditional_edges(
        <span class="str">"quality_gate"</span>,
        route_after_quality,
        {<span class="str">"compiler"</span>: <span class="str">"compiler"</span>, <span class="str">"__end__"</span>: END},
    )

    <span class="cm"># 6. Select checkpointer</span>
    <span class="kw">if</span> use_mongodb:
        checkpointer = MongoDBSaver(
            connection_string=os.environ[<span class="str">"MONGODB_URI"</span>],
            db_name=<span class="str">"neuroweave"</span>,
            collection_name=<span class="str">"checkpoints"</span>,
        )
    <span class="kw">else</span>:
        checkpointer = MemorySaver()

    <span class="cm"># 7. Compile</span>
    app = workflow.compile(checkpointer=checkpointer)
    <span class="kw">return</span> app


<span class="cm"># --- Usage ---</span>
<span class="cm"># graph = build_graph(use_mongodb=True)</span>
<span class="cm"># result = graph.invoke(initial_state, config={"configurable": {"thread_id": "ch_123"}})</span>
<span class="cm"># Or stream: for event in graph.stream(initial_state, config=...): ...</span></div>
  </div>
</section>

<!-- SECTION 10: CHECKPOINTING -->
<section class="section fade-in" id="checkpointing">
  <div class="section-header">
    <div class="section-number">Section 09</div>
    <h2 class="section-title">Checkpointing &amp; Persistence</h2>
    <p class="section-desc">Thread-level state persistence enabling cyclic re-evaluation when new messages arrive</p>
  </div>

  <div style="display:grid;grid-template-columns:1fr 1fr;gap:20px;margin-bottom:24px">
    <div class="card">
      <div class="card-icon">&#128451;</div>
      <h3>MongoDBSaver <span style="font-size:12px;color:var(--green);font-weight:500">&mdash; Production</span></h3>
      <p style="margin-top:8px">Persistent checkpoint storage for production deployments. Survives restarts, supports horizontal scaling across Celery workers.</p>
      <div class="code-block" style="margin-top:12px">
        <div class="code-body" style="font-size:12px;padding:12px"><span class="kw">from</span> langgraph.checkpoint.mongodb <span class="kw">import</span> MongoDBSaver

checkpointer = MongoDBSaver(
    connection_string=<span class="str">"mongodb://localhost:27017"</span>,
    db_name=<span class="str">"neuroweave"</span>,
    collection_name=<span class="str">"checkpoints"</span>,
)</div>
      </div>
    </div>
    <div class="card">
      <div class="card-icon">&#128171;</div>
      <h3>MemorySaver <span style="font-size:12px;color:var(--orange);font-weight:500">&mdash; Development</span></h3>
      <p style="margin-top:8px">In-memory checkpoint storage for local development and testing. Fast, zero config, but lost on process restart.</p>
      <div class="code-block" style="margin-top:12px">
        <div class="code-body" style="font-size:12px;padding:12px"><span class="kw">from</span> langgraph.checkpoint.memory <span class="kw">import</span> MemorySaver

checkpointer = MemorySaver()
<span class="cm"># No config needed</span></div>
      </div>
    </div>
  </div>

  <div class="card" style="padding:24px">
    <h3 style="font-size:15px;margin-bottom:14px">Resume Flow &mdash; How Checkpointing Enables Cyclic Graphs</h3>
    <div class="code-block" style="margin:0">
      <div class="code-header"><span class="code-lang">Python &mdash; Resuming a checkpointed graph</span></div>
      <div class="code-body"><span class="cm"># First invocation: thread is incomplete, graph checkpoints at evaluator</span>
config = {<span class="str">"configurable"</span>: {<span class="str">"thread_id"</span>: <span class="str">"discord_ch123_thread456"</span>}}
result = graph.invoke(initial_state, config=config)
<span class="cm"># result["evaluation"]["is_resolved"] == False â†’ graph ended, state saved</span>

<span class="cm"># Later: new messages arrive in the same thread</span>
updated_state = {
    <span class="str">"messages"</span>: new_messages,  <span class="cm"># Appended via Annotated[list, operator.add]</span>
    <span class="str">"threads"</span>: updated_threads,
}

<span class="cm"># Resume from checkpoint with same thread_id</span>
result = graph.invoke(updated_state, config=config)
<span class="cm"># Evaluator re-runs with the full thread including new messages</span>
<span class="cm"># If resolved now â†’ proceeds to Compiler â†’ Quality Gate â†’ END</span></div>
    </div>
  </div>
</section>

<!-- SECTION 11: OBSERVABILITY -->
<section class="section fade-in" id="observability">
  <div class="section-header">
    <div class="section-number">Section 10</div>
    <h2 class="section-title">Error Handling &amp; Observability</h2>
    <p class="section-desc">LangSmith tracing, retry policies, fallback nodes, and production metrics</p>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; observability.py</span></div>
    <div class="code-body"><span class="kw">import</span> os
<span class="kw">from</span> langsmith <span class="kw">import</span> Client
<span class="kw">from</span> langchain_core.runnables <span class="kw">import</span> RunnableConfig
<span class="kw">from</span> tenacity <span class="kw">import</span> retry, stop_after_attempt, wait_exponential
<span class="kw">import</span> structlog

logger = structlog.get_logger()

<span class="cm"># --- LangSmith Tracing ---</span>
os.environ[<span class="str">"LANGCHAIN_TRACING_V2"</span>] = <span class="str">"true"</span>
os.environ[<span class="str">"LANGCHAIN_PROJECT"</span>] = <span class="str">"neuroweave-extraction"</span>

<span class="cm"># --- Retry decorator for LLM calls ---</span>
<span class="kw">def</span> <span class="fn">with_retry</span>(func):
    <span class="str">"""Wrap a node function with exponential backoff retry."""</span>
    <span class="nb">@retry</span>(
        stop=stop_after_attempt(<span class="num">3</span>),
        wait=wait_exponential(multiplier=<span class="num">1</span>, min=<span class="num">2</span>, max=<span class="num">30</span>),
        reraise=<span class="kw">True</span>,
    )
    <span class="kw">def</span> <span class="fn">wrapper</span>(*args, **kwargs):
        <span class="kw">return</span> func(*args, **kwargs)
    <span class="kw">return</span> wrapper

<span class="cm"># --- Metrics tracking ---</span>
<span class="kw">class</span> <span class="tp">PipelineMetrics</span>:
    <span class="str">"""Track pipeline performance metrics."""</span>

    <span class="kw">def</span> <span class="fn">__init__</span>(self):
        self.processed = <span class="num">0</span>
        self.noise_filtered = <span class="num">0</span>
        self.articles_created = <span class="num">0</span>
        self.articles_rejected = <span class="num">0</span>
        self.avg_quality_score = <span class="num">0.0</span>
        self.total_processing_time_ms = <span class="num">0</span>

    <span class="kw">def</span> <span class="fn">record</span>(self, result: <span class="tp">dict</span>, duration_ms: <span class="tp">float</span>):
        self.processed += <span class="num">1</span>
        self.total_processing_time_ms += duration_ms

        <span class="kw">if</span> result.get(<span class="str">"classification"</span>) == <span class="str">"NOISE"</span>:
            self.noise_filtered += <span class="num">1</span>
        <span class="kw">elif</span> result.get(<span class="str">"quality_score"</span>, <span class="num">0</span>) >= <span class="num">0.7</span>:
            self.articles_created += <span class="num">1</span>
        <span class="kw">else</span>:
            self.articles_rejected += <span class="num">1</span>

        <span class="cm"># Running average</span>
        score = result.get(<span class="str">"quality_score"</span>, <span class="num">0</span>)
        self.avg_quality_score = (
            (self.avg_quality_score * (self.processed - <span class="num">1</span>) + score)
            / self.processed
        )

    <span class="kw">def</span> <span class="fn">summary</span>(self) -> <span class="tp">dict</span>:
        <span class="kw">return</span> {
            <span class="str">"processed"</span>: self.processed,
            <span class="str">"noise_filtered"</span>: self.noise_filtered,
            <span class="str">"articles_created"</span>: self.articles_created,
            <span class="str">"articles_rejected"</span>: self.articles_rejected,
            <span class="str">"avg_quality"</span>: round(self.avg_quality_score, <span class="num">3</span>),
            <span class="str">"avg_time_ms"</span>: round(
                self.total_processing_time_ms / max(self.processed, <span class="num">1</span>)
            ),
            <span class="str">"success_rate"</span>: round(
                self.articles_created / max(self.processed - self.noise_filtered, <span class="num">1</span>), <span class="num">3</span>
            ),
        }</div>
  </div>

  <div class="card-grid" style="margin-top:24px">
    <div class="card">
      <h3 style="color:var(--cyan)">LangSmith Tracing</h3>
      <p style="margin-top:8px">Every LLM call is traced with inputs, outputs, latency, and token usage. View full run trees in LangSmith dashboard.</p>
    </div>
    <div class="card">
      <h3 style="color:var(--orange)">Retry Policy</h3>
      <p style="margin-top:8px">Exponential backoff: 2s &rarr; 4s &rarr; 8s. Max 3 attempts per LLM call. Covers transient API errors and rate limits.</p>
    </div>
    <div class="card">
      <h3 style="color:var(--green)">Key Metrics</h3>
      <p style="margin-top:8px">Processing time, noise filter rate, article success rate, quality score distribution, retry frequency.</p>
    </div>
  </div>
</section>

<!-- SECTION 12: CELERY -->
<section class="section fade-in" id="celery">
  <div class="section-header">
    <div class="section-number">Section 11</div>
    <h2 class="section-title">Celery Integration</h2>
    <p class="section-desc">How the LangGraph pipeline is triggered asynchronously via Celery tasks for batch processing</p>
  </div>

  <div class="diagram-box">
    <div class="mermaid">
graph LR
    DISCORD["Discord Bot"] -->|"on_message"| REDIS["Redis Stream"]
    REDIS -->|"batch (50 msgs / 5 min)"| CELERY["Celery Worker"]
    CELERY -->|"invoke"| GRAPH["LangGraph Pipeline"]
    GRAPH -->|"articles"| PG["PostgreSQL + pgvector"]

    style DISCORD fill:#1a1a2e,stroke:#6366f1,color:#e4e4e7
    style REDIS fill:#1a1a2e,stroke:#ef4444,color:#e4e4e7
    style CELERY fill:#1a1a2e,stroke:#22c55e,color:#e4e4e7
    style GRAPH fill:#1a1a2e,stroke:#a855f7,color:#e4e4e7
    style PG fill:#1a1a2e,stroke:#06b6d4,color:#e4e4e7
    </div>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; tasks/process_messages.py</span></div>
    <div class="code-body"><span class="kw">from</span> celery <span class="kw">import</span> shared_task
<span class="kw">from</span> datetime <span class="kw">import</span> datetime
<span class="kw">import</span> time
<span class="kw">import</span> structlog

<span class="kw">from</span> graph <span class="kw">import</span> build_graph
<span class="kw">from</span> observability <span class="kw">import</span> PipelineMetrics

logger = structlog.get_logger()
metrics = PipelineMetrics()


<span class="nb">@shared_task</span>(
    bind=<span class="kw">True</span>,
    max_retries=<span class="num">3</span>,
    default_retry_delay=<span class="num">60</span>,
    acks_late=<span class="kw">True</span>,
)
<span class="kw">def</span> <span class="fn">process_message_batch</span>(self, channel_id: <span class="tp">str</span>, messages: <span class="tp">list</span>[<span class="tp">dict</span>]):
    <span class="str">"""Process a batch of Discord messages through the extraction pipeline.

    Triggered by Redis Stream consumer when batch threshold is reached
    (50 messages or 5 minute window, whichever comes first).
    """</span>
    logger.info(<span class="str">"processing_batch"</span>, channel=channel_id, count=len(messages))

    graph = build_graph(use_mongodb=<span class="kw">True</span>)
    start = time.monotonic()

    <span class="kw">try</span>:
        initial_state = {
            <span class="str">"messages"</span>: messages,
            <span class="str">"threads"</span>: [],
            <span class="str">"classification"</span>: <span class="str">""</span>,
            <span class="str">"evaluation"</span>: <span class="tp">None</span>,
            <span class="str">"compiled_article"</span>: <span class="tp">None</span>,
            <span class="str">"quality_score"</span>: <span class="num">0.0</span>,
            <span class="str">"retry_count"</span>: <span class="num">0</span>,
            <span class="str">"current_thread_idx"</span>: <span class="num">0</span>,
            <span class="str">"server_id"</span>: messages[<span class="num">0</span>][<span class="str">"server_id"</span>],
            <span class="str">"channel_id"</span>: channel_id,
            <span class="str">"error"</span>: <span class="tp">None</span>,
        }

        config = {
            <span class="str">"configurable"</span>: {
                <span class="str">"thread_id"</span>: <span class="str">f"batch_<span class="nb">{channel_id}</span>_<span class="nb">{datetime.utcnow().isoformat()}</span>"</span>,
            }
        }

        result = graph.invoke(initial_state, config=config)

        duration_ms = (time.monotonic() - start) * <span class="num">1000</span>
        metrics.record(result, duration_ms)

        <span class="cm"># Store successful articles to PostgreSQL</span>
        <span class="kw">if</span> result.get(<span class="str">"quality_score"</span>, <span class="num">0</span>) >= <span class="num">0.7</span>:
            store_article.delay(result[<span class="str">"compiled_article"</span>], channel_id)

        logger.info(
            <span class="str">"batch_complete"</span>,
            channel=channel_id,
            classification=result.get(<span class="str">"classification"</span>),
            quality=result.get(<span class="str">"quality_score"</span>),
            duration_ms=round(duration_ms),
        )

    <span class="kw">except</span> Exception <span class="kw">as</span> exc:
        logger.error(<span class="str">"batch_failed"</span>, channel=channel_id, error=str(exc))
        <span class="kw">raise</span> self.retry(exc=exc)</div>
  </div>

  <div class="code-block">
    <div class="code-header"><span class="code-lang">Python &mdash; tasks/generate_article.py</span></div>
    <div class="code-body"><span class="kw">from</span> celery <span class="kw">import</span> shared_task
<span class="kw">from</span> sqlalchemy <span class="kw">import</span> select
<span class="kw">import</span> structlog

<span class="kw">from</span> db <span class="kw">import</span> async_session, Article, Thread
<span class="kw">from</span> embeddings <span class="kw">import</span> generate_embedding

logger = structlog.get_logger()


<span class="nb">@shared_task</span>
<span class="kw">def</span> <span class="fn">store_article</span>(article_data: <span class="tp">dict</span>, channel_id: <span class="tp">str</span>):
    <span class="str">"""Store a compiled article in PostgreSQL with pgvector embedding."""</span>

    <span class="cm"># Generate embedding for semantic search</span>
    embedding = generate_embedding(article_data[<span class="str">"thread_summary"</span>])

    article = Article(
        channel_id=channel_id,
        symptom=article_data[<span class="str">"symptom"</span>],
        diagnosis=article_data[<span class="str">"diagnosis"</span>],
        solution=article_data[<span class="str">"solution"</span>],
        code_snippet=article_data.get(<span class="str">"code_snippet"</span>),
        language=article_data[<span class="str">"language"</span>],
        framework=article_data.get(<span class="str">"framework"</span>),
        tags=article_data[<span class="str">"tags"</span>],
        confidence=article_data[<span class="str">"confidence"</span>],
        thread_summary=article_data[<span class="str">"thread_summary"</span>],
        embedding=embedding,  <span class="cm"># vector(1536) column</span>
    )

    <span class="kw">with</span> async_session() <span class="kw">as</span> session:
        session.add(article)
        session.commit()

    logger.info(<span class="str">"article_stored"</span>, summary=article_data[<span class="str">"thread_summary"</span>][:80])</div>
  </div>
</section>

<!-- SECTION 13: FULL DATA FLOW WALKTHROUGH -->
<section class="section fade-in" id="walkthrough">
  <div class="section-header">
    <div class="section-number">Section 12</div>
    <h2 class="section-title">Full Data Flow Example</h2>
    <p class="section-desc">Step-by-step walkthrough: a real Discord conversation from raw messages to structured knowledge article</p>
  </div>

  <div class="stages">
    <div class="stage">
      <div class="stage-num">Step 1 &mdash; Raw Input</div>
      <h4>Discord Messages Arrive</h4>
      <div class="code-block" style="margin:12px 0 0">
        <div class="code-header"><span class="code-lang">Raw Discord Messages (batch of 8)</span></div>
        <div class="code-body" style="font-size:12px">[14:01] user_a3f2: Hey everyone! Happy Monday &#128075;
[14:02] user_b7c1: gm gm
[14:03] user_d4e8: Anyone seen this error with Next.js 14?
[14:03] user_d4e8: ```
Error: ENOMEM: not enough memory, fork
    at ChildProcess.spawn (node:internal/child_process:421:11)
```
[14:05] user_f1a9: @user_d4e8 yeah that's an OOM during build
[14:07] user_f1a9: Try adding this to next.config.js:
```js
experimental: { workerThreads: false, cpus: 2 }
```
[14:08] user_d4e8: @user_f1a9 omg that worked!! thanks
[14:09] user_b7c1: nice catch &#128077;</div>
      </div>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 2 &mdash; Disentanglement</div>
      <h4>Messages Clustered into 2 Threads</h4>
      <p>Sentence-BERT embeddings + cosine similarity separate the greeting from the technical discussion.</p>
      <div style="display:grid;grid-template-columns:1fr 1fr;gap:12px;margin-top:12px">
        <div style="padding:12px;background:rgba(239,68,68,.08);border:1px solid rgba(239,68,68,.2);border-radius:var(--radius-sm)">
          <div style="font-size:11px;font-weight:700;color:var(--red);margin-bottom:6px">Thread A (2 msgs)</div>
          <div style="font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace;line-height:1.7">"Hey everyone! Happy Monday"<br>"gm gm"</div>
        </div>
        <div style="padding:12px;background:rgba(34,197,94,.08);border:1px solid rgba(34,197,94,.2);border-radius:var(--radius-sm)">
          <div style="font-size:11px;font-weight:700;color:var(--green);margin-bottom:6px">Thread B (5 msgs)</div>
          <div style="font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace;line-height:1.7">"Anyone seen this error..."<br>"Error: ENOMEM..."<br>"yeah that's an OOM..."<br>"Try adding this..."<br>"that worked!! thanks"</div>
        </div>
      </div>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 3 &mdash; Router (Thread A)</div>
      <h4>Thread A &rarr; NOISE</h4>
      <p>2 messages, no code, no technical content. Claude Haiku classifies as <strong style="color:var(--red)">NOISE</strong>. Thread discarded.</p>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 4 &mdash; Router (Thread B)</div>
      <h4>Thread B &rarr; TECHNICAL</h4>
      <p>Contains stack trace, code block, @mentions. Claude Haiku classifies as <strong style="color:var(--green)">TECHNICAL</strong>. Proceeds to Evaluator.</p>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 5 &mdash; Evaluator</div>
      <h4>Assessment: Resolved</h4>
      <div class="code-block" style="margin:12px 0 0">
        <div class="code-header"><span class="code-lang">Evaluator Output</span></div>
        <div class="code-body" style="font-size:12px">{
  <span class="key">"has_solution"</span>: <span class="kw">true</span>,
  <span class="key">"has_code"</span>: <span class="kw">true</span>,
  <span class="key">"is_resolved"</span>: <span class="kw">true</span>,
  <span class="key">"reasoning"</span>: <span class="str">"User d4e8 confirmed the workerThreads fix resolved the OOM error"</span>
}</div>
      </div>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 6 &mdash; Compiler</div>
      <h4>Structured Knowledge Extracted</h4>
      <div class="code-block" style="margin:12px 0 0">
        <div class="code-header"><span class="code-lang">Compiler Output &mdash; ExtractedKnowledge</span></div>
        <div class="code-body" style="font-size:12px">{
  <span class="key">"symptom"</span>: <span class="str">"Next.js 14 build fails with ENOMEM (out of memory) error during fork"</span>,
  <span class="key">"diagnosis"</span>: <span class="str">"Default Next.js build config spawns too many worker threads, exceeding available memory on constrained environments"</span>,
  <span class="key">"solution"</span>: <span class="str">"Disable experimental worker threads and limit CPU count in next.config.js to reduce memory pressure during builds"</span>,
  <span class="key">"code_snippet"</span>: <span class="str">"// next.config.js\nmodule.exports = {\n  experimental: {\n    workerThreads: false,\n    cpus: 2\n  }\n}"</span>,
  <span class="key">"language"</span>: <span class="str">"javascript"</span>,
  <span class="key">"framework"</span>: <span class="str">"Next.js"</span>,
  <span class="key">"tags"</span>: [<span class="str">"nextjs"</span>, <span class="str">"oom"</span>, <span class="str">"enomem"</span>, <span class="str">"build-error"</span>, <span class="str">"worker-threads"</span>, <span class="str">"memory"</span>],
  <span class="key">"confidence"</span>: <span class="num">0.92</span>,
  <span class="key">"thread_summary"</span>: <span class="str">"Fix Next.js 14 ENOMEM build error by disabling worker threads"</span>
}</div>
      </div>
    </div>

    <div class="stage-connector"></div>

    <div class="stage">
      <div class="stage-num">Step 7 &mdash; Quality Gate</div>
      <h4>Score: 0.87 &mdash; PASS</h4>
      <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:8px;margin-top:12px">
        <div style="font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace">
          solution_len: 0.25<br>code_present: 0.20
        </div>
        <div style="font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace">
          confidence: 0.18<br>tags (6): 0.15
        </div>
        <div style="font-size:12px;color:var(--text-muted);font-family:'JetBrains Mono',monospace">
          diagnosis: 0.10<br><strong style="color:var(--green)">TOTAL: 0.87 &ge; 0.7 &#10004;</strong>
        </div>
      </div>
    </div>

    <div class="stage-connector"></div>

    <div class="stage" style="border-color:var(--green)">
      <div class="stage-num" style="background:var(--green)">Step 8 &mdash; Output</div>
      <h4>Article Stored in PostgreSQL + pgvector</h4>
      <p>Article is stored with a 1536-dim embedding vector for semantic search. Available via <code>/api/articles</code> and <code>/nw-ask</code> Discord command.</p>
    </div>
  </div>
</section>

<!-- FOOTER -->
<footer style="padding:40px 60px;border-top:1px solid var(--border);text-align:center;color:var(--text-dim);font-size:13px">
  <p><strong style="color:var(--text-muted)">NeuroWeave</strong> &mdash; Agent Implementation Guide v1.0 &bull; February 2026</p>
  <p style="margin-top:4px">LangGraph multi-agent pipeline for technical knowledge extraction</p>
</footer>

</main>

<script>
mermaid.initialize({
  startOnLoad: true,
  theme: 'dark',
  themeVariables: {
    darkMode: true,
    background: '#111113',
    primaryColor: '#6366f1',
    primaryTextColor: '#e4e4e7',
    primaryBorderColor: '#2a2a30',
    lineColor: '#52525b',
    secondaryColor: '#1a1a2e',
    tertiaryColor: '#111113',
    fontSize: '14px'
  },
  flowchart: { curve: 'basis', padding: 16 },
});

const observer = new IntersectionObserver((entries) => {
  entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('visible'); });
}, { threshold: 0.08 });
document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));

const sections = document.querySelectorAll('section[id]');
const navLinks = document.querySelectorAll('.nav-link');
window.addEventListener('scroll', () => {
  let current = '';
  sections.forEach(s => {
    if (window.scrollY >= s.offsetTop - 120) current = s.getAttribute('id');
  });
  navLinks.forEach(link => {
    link.classList.remove('active');
    if (link.getAttribute('href') === '#' + current) link.classList.add('active');
  });
});

navLinks.forEach(link => {
  link.addEventListener('click', () => {
    if (window.innerWidth <= 900) document.getElementById('sidebar').classList.remove('open');
  });
});
</script>
</body>
</html>
